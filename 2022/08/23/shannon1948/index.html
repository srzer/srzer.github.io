<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  
  <title>shannon1948 | Hexo</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="The fundamental problem of communication is that of reproducing at one point either exactly or approximately a message selected at another point.  The significant aspect is that the actual message is">
<meta property="og:type" content="article">
<meta property="og:title" content="shannon1948">
<meta property="og:url" content="http://example.com/2022/08/23/shannon1948/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="The fundamental problem of communication is that of reproducing at one point either exactly or approximately a message selected at another point.  The significant aspect is that the actual message is">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2022-08-23T07:34:15.000Z">
<meta property="article:modified_time" content="2022-08-30T08:59:26.139Z">
<meta property="article:author" content="John Doe">
<meta name="twitter:card" content="summary">
  
    <link rel="alternate" href="/atom.xml" title="Hexo" type="application/atom+xml">
  
  
    <link rel="shortcut icon" href="/favicon.png">
  
  
    
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/typeface-source-code-pro@0.0.71/index.min.css">

  
  
<link rel="stylesheet" href="/css/style.css">

  
    
<link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css">

  
  
<meta name="generator" content="Hexo 6.3.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Hexo</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"><span class="fa fa-bars"></span></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
        
          <a class="nav-icon" href="/atom.xml" title="RSS Feed"><span class="fa fa-rss"></span></a>
        
        <a class="nav-icon nav-search-btn" title="Search"><span class="fa fa-search"></span></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://example.com"></form>
      </div>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main"><article id="post-shannon1948" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2022/08/23/shannon1948/" class="article-date">
  <time class="dt-published" datetime="2022-08-23T07:34:15.000Z" itemprop="datePublished">2022-08-23</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="p-name article-title" itemprop="headline name">
      shannon1948
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <p>The fundamental problem of communication is that of <strong>reproducing at one point either exactly or approximately a message selected at another point</strong>. </p>
<p>The significant aspect is that <strong>the actual message is one <em>selected from a set</em> of possible messages</strong>. The system must be designed to operate for each possible selection, not just the one which will actually be chosen since this is unknown at the time of design.</p>
<p>By a communication system we will mean a system of the type indicated schematically, it consists of essentially five parts:</p>
<ol>
<li><p>information source</p>
</li>
<li><p>transmitter</p>
<p>operates on the message in some way to produce a signal suitable for transmission over the channel</p>
</li>
<li><p>channel</p>
<p> the medium used to transmit the signal from transmitter to receiver</p>
</li>
<li><p>receiver</p>
<p>performs the inverse operation of that done by the transmitter</p>
</li>
<li><p>destination</p>
</li>
</ol>
<p><strong>3 main categories:</strong></p>
<p>discrete, continuous and mixed.</p>
<h2 id="Discrete"><a href="#Discrete" class="headerlink" title="Discrete"></a>Discrete</h2><h3 id="The-discrete-noise-channel"><a href="#The-discrete-noise-channel" class="headerlink" title="The discrete noise channel"></a>The discrete noise channel</h3><p>Shannon在这里对最简单离散情况分析了频道的容量问题，并且说明了信息量的对数随时间线性增加。对于不同符号的时长不同的情况，Shannon说明了频道的容量与特征方程的最大实数根的对数相关。</p>
<p><strong>The capacity C of a discrete channel</strong><br>$$<br>C&#x3D;\lim_{T\rightarrow \infty}\frac{\log N(T)}{T}<br>$$<br>where $N(T)$ is the number of allowed signals of duration $T$.</p>
<p>Suppose all sequences of the symbols $S_1,…,S_n$ are allowed and these symbols have durations $t_1,…,t_n$. Then we have<br>$$<br>N(t)&#x3D;N(t-t_1)+…+N(t-t_n)<br>$$<br>The characteristic equation is<br>$$<br>X^{-t_1}+X^{-t_2}+…+X^{-t_n}&#x3D;1<br>$$<br>Let $X_0$ be the largest real solution of the characteristic equation. Then $N(t)\sim X_0^t$.<br>$$<br>C&#x3D;\log X_0<br>$$<br><strong>Restriction: For each state only certain symbols from the can be transmitted</strong></p>
<p><strong>Theorem 1</strong></p>
<p>Let $b_{ij}^{(s)}$ be the duration of the $s^{th}$ symbol which is allowable in state $i$ and leads to state $j$.</p>
<p>Then the channel capacity $C$ is equal to $\log W$ where $W$ is the largest real root of the determinant equation:<br>$$<br>|\sum_sW^{-b_{ij}^{(s)}}-\delta_{ij}|&#x3D;0<br>$$<br>where $\delta_{ij}&#x3D; (i&#x3D;&#x3D;j)$</p>
<h3 id="The-discrete-source-of-information"><a href="#The-discrete-source-of-information" class="headerlink" title="The discrete source of information"></a>The discrete source of information</h3><p>Shannon提出了随机过程与离散源的对等。并对离散源进行了分类。</p>
<p>A physical system, or a mathematical model of a system which produces such a sequence of symbols governed by a set of probabilities, is known as a stochastic process.</p>
<p> Conversely, any stochastic process which produces a discrete sequence of symbols chosen from a finite set may be considered a discrete source.</p>
<ol>
<li>自然语言</li>
<li>连续源经过量化</li>
<li>数学例子</li>
</ol>
<h3 id="The-series-of-approximation"><a href="#The-series-of-approximation" class="headerlink" title="The series of approximation"></a>The series of approximation</h3><p>描述了对于语言的近似方法，零阶近似（等概率任取），一阶（保持概率分布与自然语言相等），二阶（考虑前缀。。。）举了很多近似的例子后，他说，“It appears then that a sufficiently complex stochastic process will give a satisfactory representation of a discrete source.”</p>
<h3 id="各态历经混合源"><a href="#各态历经混合源" class="headerlink" title="各态历经混合源"></a>各态历经混合源</h3><p>Shannon给出各态历经(ergodic)的条件判定</p>
<ol>
<li>连通</li>
<li>circuit的长度的gcd为1，否则周期化</li>
</ol>
<p>equilibrium conditions:<br>$$<br>P_j&#x3D;\sum_{i}P_ip_i(j)<br>$$<br>In the ergodic case it can be shown that with any starting conditions the probabilities $P_j(N)$ of being in state $j$ after $N$ symbols, approach the equilibrium values as $N\rightarrow \infty$.</p>
<h3 id="Choice-uncertainty-and-entropy"><a href="#Choice-uncertainty-and-entropy" class="headerlink" title="Choice, uncertainty and entropy"></a>Choice, uncertainty and entropy</h3><p>Shannon在说明了离散信息源实质上是马尔科夫过程后，他想要导出，如何衡量产生信息的速度？</p>
<p>在已知即将发生的事件的概率的情况下，我们对结果有多大的不确定性？</p>
<p>我们来推导$H(p_i)$</p>
<p>$H(p_1,…,p_n)&#x3D;H(p_1,1-p_1)+(1-p_1)H(p_2,…,p_n)$</p>
<p>$H(\frac{1}{pq},…,\frac{1}{pq})&#x3D;H(\frac{1}{p},…,\frac{1}{p})+H(\frac{1}{q},…,\frac{1}{q})$</p>
<p>所以$H(\frac{1}{n},…,\frac{1}{n})&#x3D;K\ln n$</p>
<p>注意到一个事件产生的不确定性和其他分支没有关系</p>
<p>所以我们可以认为$p_i$的贡献是$-Kp_i\ln p_i$</p>
<p>一种表达形式：<br>$$<br>H(x,y)&#x3D;-\sum_{i,j}p(i,j)\log p(i,j)\<br>H(x)&#x3D;-\sum_{i,j}p(i,j)\log\sum_{j}p(i,j)\<br>H(y)&#x3D;-\sum_{i,j}p(i,j)\log\sum_{i}p(i,j)<br>$$<br>我们有不等式<br>$$<br>H(x,y)\le H(x)+H(y)\<br>这是怎么证的呢<br>$$<br>取等为前后两次独立。</p>
<p>$H$表现为概率越均等则越大的趋势<br>$$<br>-\sum_{i,j}p(i,j)\log p(i,j)\le -\sum_i p(i)\log p(i)-\sum_{j}p(j)\log p(j)<br>$$</p>
<p>$$<br>p_i(j)&#x3D;\frac{p(i,j)}{\sum_j p(i,j)}<br>$$</p>
<p>$$<br>H_x(y)&#x3D;-\sum_{i,j}p(i,j)\log p_i(j)<br>$$</p>
<p>这衡量了当我们知道x的时候对于y的不确定性<br>$$<br>H_x(y)&#x3D;-\sum_{i,j}p(i,j)\log p(i,j)+\sum_{i,j}p(i,j)\log \sum_{j}p(i,j)\<br>&#x3D;H(x,y)-H(x)<br>$$</p>
<p>$$<br>H(y)\ge H_x(y)<br>$$</p>
<h3 id="The-entropy-of-an-information-source"><a href="#The-entropy-of-an-information-source" class="headerlink" title="The entropy of an information source"></a>The entropy of an information source</h3><p>源的熵是状态的熵的加权平均<br>$$<br>H&#x3D;\sum_iP_iH_i\<br>H’&#x3D;\sum_i f_iH_i(per second)\<br>H’&#x3D;mH<br>$$<br>If symbols are independent, then $H$ is simply $-\sum p_i\log p_i$</p>
<p>Then consider a long message of $N$ symbols<br>$$<br>p&#x3D;\prod_{i&#x3D;1}^np_i^{p_iN}<br>$$</p>
<p>$$<br>\log p &#x3D; N\sum_{i}p_i\log p_i\&#x3D;-NH<br>$$</p>
<p><strong>Theorem 3</strong></p>
<p>Given any $\epsilon&gt;0$ and $\delta &gt;0$, we can find an $N_0$ such that the sequences of any length $N\ge N_0$ fall into two classed:</p>
<ol>
<li><p>A set whose total probability is less than $\epsilon$</p>
</li>
<li><p>$|\frac{\log p^{-1}}{N}-H|&lt; \delta$</p>
</li>
</ol>
<p>语言的冗余</p>
<h3 id="Representation-of-the-encoding-and-decoding-operations"><a href="#Representation-of-the-encoding-and-decoding-operations" class="headerlink" title="Representation of the encoding and decoding operations"></a>Representation of the encoding and decoding operations</h3><p>传感器：<br>$$<br>y_n&#x3D;f(x_n,\alpha_n)\<br>\alpha_{n+1}&#x3D;g(x_n,\alpha_n)<br>$$<br>$\alpha$表示传感器的状态</p>
<p>如果存在逆，则为非奇异</p>
<p><strong>Theorem</strong></p>
<p>传感器output的熵$\le$ input的熵，当且仅当非奇异时取等</p>
<p>然后讨论了通过适当的转移概率分配，信道上符号的熵可以最大化</p>
<p><strong>Theorem</strong></p>
<p>Source has entropy $H$, channel has capacity $C$. Then the average rate can be $\frac{C}{H}-\epsilon$, not greater than $\frac{C}{H}$.</p>
<p>不能超过这是因为每秒传输器传的熵等于源的熵，小于等于频道容量。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2022/08/23/shannon1948/" data-id="clkv75d2f000qxg1o4iu1gmcj" data-title="shannon1948" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2022/08/28/Reading-Note-of-What-is-Life/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          读书笔记-生命是什么？
        
      </div>
    </a>
  
  
    <a href="/2022/08/23/Reading-notes-of-idiot/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">读书笔记-白痴</div>
    </a>
  
</nav>

  
</article>


</section>
        
          <aside id="sidebar">
  
    

  
    

  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/02/">February 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/01/">January 2023</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/12/">December 2022</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/11/">November 2022</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/10/">October 2022</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/09/">September 2022</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/08/">August 2022</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/07/">July 2022</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/03/">March 2022</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/02/">February 2022</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/01/">January 2022</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/09/">September 2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/08/">August 2021</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2023/02/14/Reading-Note-of-The-Karamazov-brothers-2/">读书笔记-卡拉马佐夫兄弟(二)</a>
          </li>
        
          <li>
            <a href="/2023/01/28/Reading-Note-of-The-Karamazov-brothers-1/">读书笔记-卡拉马佐夫兄弟(一)</a>
          </li>
        
          <li>
            <a href="/2022/12/16/12-16%E9%9A%8F%E7%AC%94/">12-16随笔</a>
          </li>
        
          <li>
            <a href="/2022/11/23/11-23%E9%9A%8F%E7%AC%94/">11-23随笔-利维坦</a>
          </li>
        
          <li>
            <a href="/2022/11/09/11-9%E9%9A%8F%E7%AC%94/">11-9随笔-利维坦笔记</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      
      &copy; 2023 John Doe<br>
      Powered by <a href="https://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    


<script src="/js/jquery-3.6.4.min.js"></script>



  
<script src="/fancybox/jquery.fancybox.min.js"></script>




<script src="/js/script.js"></script>





  </div>
</body>
</html>